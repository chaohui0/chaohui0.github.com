---
layout: post
title: ASR实现源码解读
description: asr
category: blog
---

上一篇文章讲了ASR的识别过程，本篇讲一讲ASR CTC方式具体工程实现的一些逻辑。首先丢一个贝叶斯公式：

\(P(W|O) = \frac{P(W) * P(O|W)}{P(W)}\)
 
 其中，W表示任一单词，O表示输入的语音序列（Observation Sequence）。P(W)是语言模型获得的，\(P(O|W)\)由语音模型获取。

采用了CTC模型后，使用深度学习模型替代了原先的HMM和GMM，根据音频特征直接计算phone的概率。所以声学模型（Acoustic Model， AM）就是一个前向计算模块，输入为每一帧的音频特征，输出每一帧对应的121个phone的概率，这部分的实现逻辑相对是简单的，主要复杂度在模型训练。

在具体实现中，语言模型会生成一个LG网络，G网络是指语言模型的网络，LG网络是将发音词典整合到G网络，得到了LG网络，表示方法为一个五元组：

from_state to_state input output weight

其中state是一个抽象的概念，用于描述一个状态跳转的概念。在LG网络中input是phone，output是word(当然在工程实现的时候会用word_id表示）。weight则是语言模型的权重，LG网络可以用kaldi工具生成。

有了每一帧的phone概率和LG网络，就可以实现解码了，可以使用Token Passing来实现Viterbi算法。简单描述下，所有搜索从state=0开始，这时候从LG网络中找到所有from_state=0的边，比如有n个input phone，可以从AM输出中找到对应的phone概率，而weight就是LM的概率，两者的乘积其实就是output的概率，而上面讲了output就是我们要的word，是不是很简单！如果只是为了吹牛逼，你看到这里已经足够了。是的，讲道理都很简单，要写两行代码就知道没啥卵用。后面抽空详细讲一讲代码实现的一些问题。

未完待续。。。

