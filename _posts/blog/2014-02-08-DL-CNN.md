---
layout: post
title: Convolutional Neural Networks
description: Deep Learning学习系列之LeNet
category: blog
---

了解了一点神经网络的皮毛后，开始Deep Learning相关的学习，这个过程就像是学了一个select或者epoll的unix系统调用就开始写一个搜索引擎啊。

回顾一下，一个简单的神经网络包含input layer、多个hidden layer，还有ouput layer，layer中的包含activation节点，每层的activation节点计算结果输出作为一下层的节点输入（通常使用全连接，即输出给每个下一层的节点）。理了一下就可以知道，在实际使用中，可以做的变化主要就是两个：计算节点的计算函数；layer之间的连接方式。

然后，开始介绍卷积神经网络，直接上图
![cnn](/images/cnn.jpeg)

这是该算法应用最成功的手写识别模型，可以发现主要有两大部分组成：Convolution-Subsampling 部分和Full connection部分。然后开始一层一层讲解，如有不当之处请指正。

首先INPUT是32*32的图片转换到C1中的6个特征映射的28*28矩阵，这一步是一个Convolution过程，需要156个训练参数，怎么算出来的呢，首先每个特征映射都有一个5*5的模板，然后加上一个bias参数（也就是一个常量参数），这样每层就是5*5+1=26个参数，然后6层26*6=156了。

然后是C1到S2的降采样过程，这一步需要12个参数，降采样的过程是使用一个2*2的模板在C1上滑动，将模板内的4个值相加得到Σ，然后每个模板使用两个参数a*Σ+b计算获得S2中对应的值，这样每层就是2个参数，2*6=12。

然后S2到C3的卷积过程，需要1516个参数，这个过程需要看下图来理解
![s2c3](/images/s2c3.jpeg)
横轴表示16个C3节点，竖轴表示6个S2输入节点，数了下XX个数是60，表示总共需要60个5*5模板，所以60*5*5+16个bias参数，总共为1516个参数。

C3到S4类似C1到S2，32个参数，不赘述。

S4到C5是一个全链接的卷积过程，即C5中的120个节点与S4的16层全链接做卷积，所以需要的参数是16*5*5*120+120个bias参数，总共为48120个参数。

C5到F6和F6到OUTPUT也是全连接，根据开始描述的传统的神经网络模型，我们可以知道F6需要84*120+84=10164个参数以及OUTPUT需要84*10+10=850个参数。


### Caffe

然后介绍下牛逼的卷积神经网络的工具：Caffe
官方主页：[http://caffe.berkeleyvision.org/](http://caffe.berkeleyvision.org/)

里面包含手写识别和imageNet1000个分类的demo代码，可参照修改解决具体的问题。

安装完成后，可以新建一个文件夹用来做具体的分类问题，主要分两个步骤：数据预处理和训练。数据预处理包括将图片转为leveldb格式的文件以及mean file的计算。

	echo "convert images to leveldb..."
	
	../build/examples/convert_imageset.bin /home/data/ train.txt trainDB
	../build/examples/convert_imageset.bin /home/data/ test.txt testDB
	
	echo "begin to calculate leveldb mean file..."
	../build/examples/demo_compute_image_mean.bin trainDB train_mean.binaryproto

训练的代码就一行

	echo "begin to train ...."
	
	GLOG_logtostderr=1 ../build/examples/train_net.bin imagenet_solver.prototxt

然后需要配置几个prototxt文件，主要是改下输入文件和输出类目个数等。

然后就开始三天三夜的等待吧。



[LinChaohui]:    http://www.linchaohui.com  "LinChaohui"
