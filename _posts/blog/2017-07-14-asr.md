---
layout: post
title: ASR语音识别
description: asr
category: blog
---

印象笔记不能用，只能在这里记录下了。最近在做ASR的东西，花了两个星期终于把整个解码架构理解了下，整理下发出来，如有错误请指出。还有就是越来越觉得，不管多复杂的问题，如果一个人不能用白话给你讲清楚的话，那说明他其实理解的也不深入。

一张图解释整个解码过程
![asr](/images/asr.png)

1.首先是特征提取，把原始的音频分帧，FFT频谱分析，Mel滤波，倒谱分析等一堆处理，最终变为一个几十维的数值向量。（详请可搜索关键词MFCC）

2.Frame到State，这一步是整个过程最难理解的地方，这里用到了一个Acoustic Model，也就是语音模型，一提到语音模型，基本上搜索结果返回的都是首先详细讲解下HMM和GMM，然后一笔带过说这两个组合一下就是语音模型了，我你妹啊。做为一个从一无所知的，但是经过自己苦思终于把这两个东西想通的过来人，我觉得还是有必要用人话把这个讲一下的，是的，后面不会出现公式，因为你应该已经百度过HMM和GMM了把，如果没有，请先去谷歌下，再来看后续分析。首先需要知道HMM的隐状态就是这里的State，而观测状态就是第一步生成的MFCC特征，而GMM就是从一个state到一个MFCC特征的观测概率分布。是不是一句话就把问题讲清楚了！聪明如你，坑定想问那state是什么呢，怎么理解这个state呢。其实这里有必要深入HMM的隐状态的含义，HMM为什么要有隐状态和观测状态，隐状态的引入其实是希望能有一个抽象状态可以对某一类观测出现的观测概率高。好想有点绕口，举个例子，那个桶里拿红白球的例子，如果一个桶里全是红球，一个桶里全是白球，那是不是一个隐状态就能对应一个观测状态了呢，如果两个桶里都是一半白球一半红球，你还HMM个毛线，用什么算法都分不出来了。所以HMM其实有聚类的思想在里面的，如果某一类隐状态可以很高概率对应到某一类观测变量，那这个HMM就是成功的！熵就是最低的！得出的结果就是可信的！State通过对triphone做决策树生成，每个叶结点的triphone就有相似的语音特性，也就是一个state
，那这样对应某一种观测特征的概率就会大一些。就可以根据音频特征计算state，再通过state 得到对应的phone。

3.后面的内容就比较简单了，lexicon是根据phone对应到word，语言模型就是n-gram加上蛋疼的各种平滑，这样一条链路下来就可以得到各种条件概率了。

4.最后轮到WFST出场了，WFST的作用就是把上面的语音模型，lexicon，语言模型都转成WFST，然后再合并，优化等操作后进行加速解码。

最后总结一下：
解码过程首先是根据音频文件提特征（固定长度比如10ms），然后通过维特比算法通过Frame特征计算最大概率state隐状态序列，通过state对应到具体的phone，（state就是根据triphone使用决策树聚类生成的，另外有了state和对应的Frame，训练HMM和GMM那是另外一个问题），然后根据词典将phone对应到word，通过语言模型获得word的概率。一连串的递推就得到Frame->word的概率了，说起来简单，用起来还是有很多蛋疼的细节。还是深度学习大法好，直接一个神经网络Frame就能得到word。


[LinChaohui]:    http://www.linchaohui.cn  "LinChaohui"
