---
layout: post
title: 无处不在的贝叶斯
description: 新系列(二)
category: blog
---
上一篇最后举了个计算抛硬币的计算概率的例子，其实就是传统的频率方法，而与之对应的就是目前比较流行的贝叶斯方法。如上文讲的，频率学派的所有统计推断基于中心极限定理与大数定律，当样本无穷大的时候，频率就等于概率，但是，在现实生活中，上哪搞这么多样本呢。比如你今年高考考上北大的概率是多少啊？频率学派就让你考100次，然后用考上的次数除以100。而贝叶斯学派会找几个高考特级教师对你进行一下考前测验和评估，然后让这几个教师给出一个主观的可能性，比如说：你有9成的把握考上北大。目前贝叶斯学派的应用很广，比如说预测美国总统竞选成功的概率，巴西下届世界杯夺冠的概率，明天下雨的概率，运载火箭发射成功的概率，等等。而这些事件的概率，频率学派是无法进行估计的，因为这些事件不可能在相同条件下重复。贝叶斯方法相比频率方法多引入了先验概率这玩意，即哪几个高级教师的个人经验，或者科学家们的先验知识等等。由此引出后续的了共轭分布，beta分布，Dirichlet分布，Markov chain Monte Carlo，Gibbs Sampling，LDA主题模型等一系列的东西。

回到贝叶斯上，其表达式为：\\(P(\theta\|X) = \frac{P(\theta) * P(X\|\theta)}{P(X)}\\),其中\\(P(\theta)\\) 就是先验分布，\\(P(X\|\theta)\\)是条件概率，P(X)叫边缘概率，\\(P(\theta\|X)\\) 就是后验概率。看到这里，一切似乎还是很熟悉的，脑子里不自觉的回想起考概率论时候好坏车床生产螺丝的概率计算问题。然后，还是以抛硬币为例，贝叶斯学派的人怎么去预测出现正面的概率呢。看了下很多人的[博客](http://maider.blog.sohu.com/306392863.html),大家似乎都是这么说的，选取一个Beta分布作为先验分布，然后似然函数为一个二项式分布，两个一乘再除以边缘概率得到一个也是Beta分布的后验概率分布。故事似乎可以这么简单一句就讲完了，除了搞不明白为什么用个丑到让人头大的Beta函数、以及为什么用Beta就共轭了呢。当然，虽然Beta函数丑，但看多了也就习惯了嘛。至于共轭，这就是一个定义，推导一下确实就是这么回事。好像一切都清晰了，于是，我提了一个问题，如果先验不用Beta分布呢，比如我坚持的认为，抛硬币出现正面的概率坑定是0.5嘛，把这个作为先验算下后验概率吧，为了简化计算，条件变成抛了4次，出现1次正面吧。当我微微一笑提起笔开始算了几分钟后，开始抓狂了，尼玛，这是什么情况，我连怎么把这个问题用数学形式写出来都不知道！！然后发现自己的原先的认知金字塔开始一层层的倒塌，好像什么都不懂啊！尼玛！于是决定从最底层开始重新搭建。就从哲学的角度开始思考概率到底是什么吧。等等，为什么写个贝叶斯都扯到哲学了！引述下[这篇博客](http://www.52ml.net/13565.html)中的几条核心观点，首先定义了概率论里的基本事件空间：   
1、  空集（空事件）在A中，X（全事件）在A中    
2、  如果a事件在A中，那么a的补集（“a事件不发生”这一事件）也在A中。    
3、  如果有a1、a2、a3、……、an这些事件（可以是可数无穷个！）在A中，那么“它们都或许发生”这一事件（即全部取并集）也在A中。    

然后，我们就可以度量这些事件的“长度”——也即它们的概率。用的工具就是测度——在这里也可以看成“概率测度”。这种说法确实有种眼前一亮的感觉。但是休谟却说“过去每天早上太阳从东方升起，所以明天早上太阳还会从东方升起，这是不靠谱的”，进而把归纳法批了一通，比如说我们统计是做了N次重复独立的实验，然后balbala，但休谟说，你说重复独立就重复独立啊。然后头就有点大了，还是回到正常人的思维上来把。

在[这篇博客](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)中讲的很好，费了了老劲看完后，恍然大悟，原来是这样，终于可以回到抛硬币的问题上来了。解：假设我认为先验就是正面的概率=0.5，而不是一个什么分布，那先验\\(P(\theta)=1\\),其中\\(\theta\\)表示正面的概率=0.5这个事件，有没有感到一种深深的恶意！\\(P(\theta)\\)其实表示的是概率的概率分布，而我傻傻的把先验当成了一个独值离散分布！硬着头皮继续下去吧，然后\\(P(X\|\theta)\\)表示的是正面的概率=0.5的情况下，出现X，也就是抛四次有一次正面的概率，很简单的伯努利分布：\\(C_{4}^1 (0.5)^1\*(1-0.5)^3\\),P(X)表示在各种先验\\(\theta_i\\)的情况下，\\( \sum P({\theta}_i)\*P(X\|{\theta}_i)\\),这里就一种情况，所以\\(P(X)=1\*C_{4}^1(0.5)^1\*(1-0.5)^3\\)。三个值都有了，好嘛，一算结果\\(P(\theta\|X) = 0.5\\) ，而且其实不管X怎么样，结果都是0.5。终于深刻的体会了这句话：贝叶斯这个式子的抽象含义是：对于给定观测数据，一个猜测是好是坏，取决于“这个猜测本身独立的可能性大小（先验概率，Prior ）”和“这个猜测生成我们观测到的数据的可能性大小”（似然，Likelihood ）的乘积。对于这个实验，表明如果我坚定的主观认为出现正面的概率一定是0.5，不管是不是假币还是灌铅的骰子神马的，那不管实验结果怎么样都不会改变我的想法，这就所谓的脑残没药医么，去了澳门死都不知道怎么死的啊，怪不得逢赌必输。平静了一下之后，我又提出了一个问题，是的，我承认第一个问题有点sb，第二个问题改进了一下，人不能冥顽不灵，先验变成了两种情况：\\(\theta_1\\) 表示正面的概率=0.5和\\(\theta_2\\)表示正面的概率=0.25，并认为这两种情况是等可能的（不要问为什么，随便拍脑袋的）。在来算一遍后验吧。两种情况分别计算，\\(P(\theta_1)=0.5\\)，\\(P(X\|\theta_1)=C_{4}^1(0.5)^1\*(1-0.5)^3\\), \\(P(X)=P(X|\theta_1)*P(\theta_1) + P(X|\theta_2)*P(\theta_2)\\),提笔一算，后验\\(P(\theta_1\|X)=16/43\\),结果竟然变小了，而对应的\\(P(\theta_2\|X)\\)的也就变大了。这意味着什么，我陷入了深深的思考，如果做一百次试验呢，每次试验都是抛4次出现一次正面，那我们的原先的偏见就会被改变，所以千万不要做一个自以为是的傻*，心中要装下无限的可能，然后让历练来优化自己的思想，而固执己见的傻*是无法沟通的，不要尝试去改变他们，当然这部分人中也可能存在一小部分先验经验就是等于真实概率的天才。怪不得说那些思想奇葩的不是傻*就是天才，原来这是可以用数学推导出来的！哈哈哈哈。离散分布的情况想清楚后，连续实数域的情况就可以类推了，而贝叶斯流派在机器学习中应用太多了，不过万变不离其宗，必须深入的理解这个公式的内涵。




[LinChaohui]:    http://www.linchaohui.com  "LinChaohui"
