---
layout: post
title: svm学习笔记 
description: 具有更多积木，才能搭出摩天大厦
category: blog
---

##一点前言

app马上就要发布，后面开始机器学习相关的工作，这是当年毕业的时候最想做的东西，结果等了这么久才开始相关的学习。之前零零碎碎看了一些Andrew Ng教授的视频和一些blog，开始一步步思考，整理，归纳，记录吧。

##初始SVM

SVM(Support Vector Machine)听了很久了，但没见过。首先还是学习一些名词解释吧。

http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html

这篇文章比较浅显的讲解了一些基本概念，个人总结一下：

什么叫Support Vector：就是在线性分类中，距离分割线（或者分割超平面）距离最近的点。

Maximum Marginal: 使分割间隙最大化，这是分类器所最求的目标，其实也就是使support vector 距离分割线越远越好。

过拟合（over-fitting): 记得Ng的视频里讲，过拟合是指训练时，为提高对训练集的分类准确度，生成的分类函数过于复杂（也可能是没有去除噪声等干扰等导致），比如一条直线就可以基本准确分类的却使用二次曲线，这样可能训练集的分类准确度很高，但实用效果并不好。（个人理解,如有错误请指正）

欠拟合（under-fitting): 与过拟合相反，使用的分类函数过于简单，比如最优应该是3次函数的，确使用2次函数或直线（个人理解，大数据训练集才是王道）

核函数：碰到线性不可分的情况怎么办，让空间从原本的线性空间变成一个更高维的空间，在这个高维的线性空间下，再用一个超平面进行划分，这就需要核函数的帮忙了，先知道有这么个东西就可以了。

数学证明神马的可以参看该blog：

http://blog.csdn.net/v_july_v/article/details/7624837

--------------------------------------------------------------

下一步应该是用opencv的svm了吧，理论和实践总是有差距的。等熟练下再做个svm编程实践的记录吧。

