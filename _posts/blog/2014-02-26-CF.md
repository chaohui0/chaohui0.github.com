---
layout: post
title: 推荐引擎
description: mahout介绍及淘宝类目推荐实验
category: blog
---
###扯淡的前言

最近又开始搞推荐引擎，方向切换快的目不暇接啊，没办法，跟着需求走，谁让咱是社会主义一块砖呢。

幸好之前看了机器学习的课程，对协同过滤这些理论还是有概念的，之前也写过hadoop的M/P程序，应该说还是比较适合的，而且这块东西要的急，只能快速上手接下来了。

而真正让我对这个事很有兴趣的是听说了一个事，公司主营的业务是根据淘宝的一张商品图片找到同款商品，也就是一个相似图片搜索技术。而之前有个实习生做了个超简单的推荐系统，然而这两个产品在实际应用中统计到点击率竟然非常接近。这让我很是思考了一阵，一个是投入了很多人力时间，综合了很多复杂算法的技术，一个是一个人花几个星期写的，理论模型可以10分钟讲清楚的，而且是有点基本计算机知识的就能清楚的技术，为什么在商业价值的评价标准之一--点击率上，会这么相近。

能想到的一个观点是，将实际需求和技术能力看成两个向量，它们的点积才是其整体的价值，也就是说这个技术是要能满足这种需求的，即跟这个需求是同方向的，那才能产生最大的价值，而购物这种需求显然并不是只有一个找同款的技术能满足的，推荐技术也许更能满足其需求，所以只需要很少的技术能力就能产生较大的价值。


###mahout安装

OK，扯得有点多，回到正题，做推荐当然应该知道mahout了，使用mahout的第一步当然是安装它了。安装的资料网上还是很多的，依次安装jdk、maven、hadoop、mahout，基本流程就是上官网下载，解压，改系统变量，改配置文件，运行测试。主要是安装hadoop会出现一些问题，特别是配置文件的修改，可参考[链接](http://blog.csdn.net/dingdn/article/details/13000183)，在测试运行hadoop的时候，一个经验是关闭后不要马上启动，不然可能修改的配置无法生效，要出了问题一个万能解决方案就是就把tmp和log下的文件全部删掉再启动。这次碰到一个hdfs没有自动生成/user/hadoop目录，导致put不成功，搞了半天，最后dfs -mkdir这个目录就ok了。其他一些常识比如必须要用hadoop用户名之类也要注意下。如果几个测试例子都跑了下没问题那就说明安装成功了。

###协同过滤

安装完后跑了几个demo还是有点成就感的，然后就磨拳擦掌的进入了不知道怎么开始的状态了把。还是先了解下一些理论吧，比如[协同过滤](https://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy2/)。

最常用的协同过滤主要是两种：userbase和itembase。     
总结了一下，userbase计算的是用户相似度，所以推荐的步骤是：

1）根据目标用户找到跟其相似的用户；     
2）将相似用户关联的商品推荐给目标用户。     

所以是一个 人-人-物 的过程，主要的计算在第一步的人-人关系矩阵上。

itembase计算的是商品间的相似度，其推荐步骤是：

1）获取目标用户的关联商品；  
2）根据商品相似度，推荐与目标用户的关联商品相似度最大的商品。   

所以是一个 人-物-物 的过程，主要的计算在第二步的物-物关系矩阵上。

itembase中又有一个系列叫Slope One，该方法运用f=x+b的形式来评价项目之间的相似度，
具体wiki一下。

userbase和itembase算法都属于Memory Based的协同过滤技术。还有Model based的算法，比如Latent Semantic Indexing 和Bayesian Networks等。

###动手写个推荐

明白理论后，就跃跃欲试的想自己动手写个推荐系统。项目要求的是给用户推荐商品类目，首先要分析采用哪种算法，由于面对的问题是用户不稳定而类目稳定的，所以采用itembase是显然的。主要就是分析日志，将每个用户点击过的类目统计出来。然后构造个item的二维矩阵，当一个用户同时点过两个类目就将两个类目关联度加1。这样就可以得到一个类目关系矩阵了，其思想很简单，当大量的用户同时点选了两个类目，就认为这两个类目是相关联的。然后将这个矩阵归一化或者计算一个余弦相似度，排个序就over了，实际效果还是不错的,部分结果如下图，有兴趣可以点击[链接](/documents/log.txt)查看完整的结果，还是能发现一些有意思的东西，部分类目没有收录所以不知道具体的名称。    
![owncf](/images/owncf.png)

###基于mahout的CF实现

当然，mahout已经实现了itemBase和userBase的算法，我们不需要花大量的时间去重复制造轮子，对于一些简单的需求，直接调用api就可以了。

####itemBase的示例代码    
     
	import java.io.BufferedWriter;
	import java.io.File;
	import java.io.FileWriter;
	import java.io.IOException;
	import java.util.List;

	import org.apache.mahout.cf.taste.impl.common.LongPrimitiveIterator;
	import org.apache.mahout.cf.taste.impl.model.file.FileDataModel;
	import org.apache.mahout.cf.taste.impl.recommender.GenericBooleanPrefItemBasedRecommender;
	import org.apache.mahout.cf.taste.impl.similarity.LogLikelihoodSimilarity;
	import org.apache.mahout.cf.taste.model.DataModel;
	import org.apache.mahout.cf.taste.recommender.ItemBasedRecommender;
	import org.apache.mahout.cf.taste.recommender.RecommendedItem;
	import org.apache.mahout.cf.taste.similarity.ItemSimilarity;

	public class Itembase {
		
		public void process(String inputFile, String outputData, String recommendItemNum) {

			BufferedWriter bw = null;
			try {
				DataModel dataModel = new FileDataModel(new File(inputFile));
				ItemSimilarity similarity = new LogLikelihoodSimilarity(dataModel);
				ItemBasedRecommender recommender = new GenericBooleanPrefItemBasedRecommender(dataModel, similarity);
				LongPrimitiveIterator it = dataModel.getItemIDs();

				bw = new BufferedWriter(new FileWriter(new File(outputData)));
				while (it.hasNext()) {
					long baseItemId = it.next();
					List<RecommendedItem> recommendResult = recommender.mostSimilarItems(baseItemId,
							Integer.valueOf(recommendItemNum));
					StringBuilder sb = new StringBuilder();
					for (RecommendedItem recommendedItem : recommendResult) {
						sb.append("," + recommendedItem.getItemID());
					}
					bw.append(baseItemId + sb.append("\n").toString());
				}
				bw.flush();
			} catch (Exception e) {
				System.out.println("处理文件:【" + inputFile + "】失败");
			} finally {
				if (bw != null) {
					try {
						bw.close();
					} catch (IOException e) {
						e.printStackTrace();
					}
				}
			}

		}
		
		public static void main(String[] args) throws Exception { 
			
		}
	}


####userBase的示例代码    
    	
	import org.apache.mahout.cf.taste.impl.model.file.*;   
	import org.apache.mahout.cf.taste.impl.neighborhood.*;   
	import org.apache.mahout.cf.taste.impl.recommender.*;   
	import org.apache.mahout.cf.taste.impl.similarity.*;   
	import org.apache.mahout.cf.taste.model.*;   
	import org.apache.mahout.cf.taste.neighborhood.*;   
	import org.apache.mahout.cf.taste.recommender.*;   
	import org.apache.mahout.cf.taste.similarity.*;   
	import java.io.*;   
	import java.util.*;

	public class Userbase{
	public static void main(String[] args) throws Exception {   
		
			DataModel model = new FileDataModel(new File("item.csv")); //A   
			UserSimilarity similarity = new PearsonCorrelationSimilarity(model);   
			UserNeighborhood neighborhood =   
			new NearestNUserNeighborhood(4, similarity, model);   
			Recommender recommender = new GenericUserBasedRecommender(   
			model, neighborhood, similarity); //B   
			List<RecommendedItem> recommendations =   
			recommender.recommend(1, 1); //C   
			for (RecommendedItem recommendation : recommendations) {   
			System.out.println(recommendation);   
			}
			}
	}  


  
对于淘宝类目推荐的问题，可以采用itemBase的算法，查看[实验结果](/documents/cfResult.txt)并对比效果可以发现还是略优于自己写的算法的。

当然，这只是使用了mahout中的taste库的一段单机版代码。mahout真正能大显身手的应当是结合MapReduce的分布式推荐计算，有机会留待后续完善吧。



[LinChaohui]:    http://www.linchaohui.com  "LinChaohui"
