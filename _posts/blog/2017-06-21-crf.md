---
layout: post
title: CRF
description: 新系列
category: blog
---

## CRF的理解

CRF模型的本质是计算p(y|x),所以是一种判别模型，逻辑回归也是一种判别模型，其实从这个角度看，逻辑回归的本质也是计算p(y|x)，其计算方式是f(w*x+b)，f是logistic函数，x是一个特征序列。
如果很深入的理解了这个公式，就可以很直接的联想到CRF的特征函数，对应到CRF，p(y|x)的计算方式是，1/z* exp(ut+vs)，其中t为转移函数，设为状态函数。
懂了就可以意会了，公式就自己查下。如果对CRF中的特征函数没有领悟，说明还对判别模型没有领悟。生成模型和判别模型的本质区别在于前者假设y决定x，后者假设x决定y。

逻辑回归中的x特征序列用来描述当前状态，这里的CRF特征函数也是一样的，其中s就是定义在观察状态上的状态特征，不同的是，这里加了一个t表示转移特征，这个t是与前后一个状态有关的（条件随机场通用意义上应该是跟有连接的状态有关，这里是线性链随机场，所以只跟前一个后一个有关），这就增加了复杂度了。理解了这个模型之后，求解训练过程就可选择性学习下了。
每个模型分开来理解似乎已经比较清楚了，下面就是融会贯通的时刻，比如crf与hmm到底有什么关系呢，一开始看到有人说hmm与crf说可以等价的，我是拒绝的，因为两者本质上的思想还是有点不同的，hmm是一种生成模型，crf是判别模型，hmm是求：状态->状态的转移矩阵，和状态->观察 的观察矩阵（本质是计算P(x|y))，而crf是通过观察数据和状态标注直接计算p(y|x)，hmm中有隐状态，crf是不会有未标注数据的。那为什么会说他们是可以等价的，这就需要更进一步的高层抽象理解了。

http://freemind.pluskid.org/machine-learning/discriminative-modeling-vs-generative-modeling/

http://www.research.ed.ac.uk/portal/files/10482724/crftut_fnt.pdf

这两篇文章解释了一个概念：generative discriminative pair

朴素贝叶斯和逻辑回归是一对，hmm和crf是一对

朴素贝叶斯的假设是条件概率独立所以下面的三个特征x之间是没有关系的，而logistic的假设是线性模型。

但crf的关键问题是特征函数，怎么设计特征函数直接决定了最终的效果，这也导致了这不是一个纯粹的自动的通用的模型。

这个时候就到了深度学习登场的时候到了，深度学习是一个端到端的模型，只需要数据和目标，就可以拟合目标函数，而对比传统模型，其模型结构是固定的，所以最重要的环节就是特征生成。
http://blog.sciencenet.cn/blog-1225851-900232.html





[LinChaohui]:    http://www.linchaohui.cn  "LinChaohui"
